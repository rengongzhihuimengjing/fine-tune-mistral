{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rengongzhihuimengjing/fine-tune-mistral/blob/main/Phixtral_Inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title # Phixtral inference\n",
        "\n",
        "# @markdown Quick notebook to run [mlabonne/phixtral-2x2_8](https://huggingface.co/mlabonne/phixtral-2x2_8) (recommended) and [mlabonne/phixtral-4x2_8](https://huggingface.co/mlabonne/phixtral-4x2_8) on a free T4 GPU in 4-bit precision.\n",
        "\n",
        "!pip install -qqq --upgrade transformers einops accelerate bitsandbytes --progress-bar off\n",
        "\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model_name = \"phixtral-2x2_8\" # @param [\"phixtral-2x2_8\", \"phixtral-4x2_8\"]\n",
        "instruction = \"Write an epic poem about Ancient Rome.\" # @param {type:\"string\"}\n",
        "\n",
        "prompt = f'''\n",
        "<|im_start|>system\n",
        "You are Phixtral, a helpful AI assistant.<|im_end|>\n",
        "<|im_start|>user\n",
        "{instruction}<|im_end|>\n",
        "<|im_start|>assistant\n",
        "'''\n",
        "\n",
        "torch.set_default_device(\"cuda\")\n",
        "\n",
        "# Load the model and tokenizer\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    f\"mlabonne/{model_name}\",\n",
        "    torch_dtype=\"auto\",\n",
        "    load_in_4bit=True,\n",
        "    trust_remote_code=True\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    f\"mlabonne/{model_name}\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "# Tokenize the input string\n",
        "inputs = tokenizer(\n",
        "    prompt,\n",
        "    return_tensors=\"pt\",\n",
        "    return_attention_mask=False\n",
        ")\n",
        "\n",
        "# Generate text using the model\n",
        "outputs = model.generate(**inputs, max_length=200)\n",
        "\n",
        "# Decode and print the output\n",
        "text = tokenizer.batch_decode(outputs)[0]\n",
        "print(text[len(prompt):])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtOUpXoOs6t9",
        "outputId": "11c90435-a5e7-4732-8f76-6958a95a30ff",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In the heart of the ancient world, where the sun kissed the earth,\n",
            "Lived a civilization of grandeur, a tale of might and of birth.\n",
            "Ancient Rome, a city of marble and gold,\n",
            "Where heroes rose and fell, their stories untold.\n",
            "\n",
            "In the days of the Republic, when the Senate was strong,\n",
            "The great Julius Caesar, a leader of the throng.\n",
            "With legions of soldiers, he conquered lands afar,\n",
            "And his name echoed through the ages, like a clarion call.\n",
            "\n",
            "Then came the days of the Empire, when Rome grew,\n",
            "With emperors like Augustus, who ruled with a golden glow.\n",
            "He built the Colosseum, where gladiators fought,\n",
            "And the Forum, where citizens gathered, their voices resolute.\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}